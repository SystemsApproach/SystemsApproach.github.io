
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>6.3 TCP Congestion Control Â· Computer Networks: A Systems Approach</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-block-align/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-smart-nav-collapse/smart-nav-collapse.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
        <link rel="stylesheet" href="../styles/website.css">
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="avoidance.html" />
    
    
    <link rel="prev" href="queuing.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Preface
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../foundation/problem.html">
            
                <a href="../foundation/problem.html">
            
                    
                    Chapter 1: Foundation
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../foundation/applications.html">
            
                <a href="../foundation/applications.html">
            
                    
                    1.1 Applications
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../foundation/requirements.html">
            
                <a href="../foundation/requirements.html">
            
                    
                    1.2 Requirements
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../foundation/architecture.html">
            
                <a href="../foundation/architecture.html">
            
                    
                    1.3 Architecture
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../foundation/software.html">
            
                <a href="../foundation/software.html">
            
                    
                    1.4 Software
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../foundation/performance.html">
            
                <a href="../foundation/performance.html">
            
                    
                    1.5 Performance
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="../foundation/summary.html">
            
                <a href="../foundation/summary.html">
            
                    
                    1.6 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../direct/problem.html">
            
                <a href="../direct/problem.html">
            
                    
                    Chapter 2: Direct Connections
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../direct/perspective.html">
            
                <a href="../direct/perspective.html">
            
                    
                    2.1 Perspective on Connecting
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../direct/encoding.html">
            
                <a href="../direct/encoding.html">
            
                    
                    2.2 Encoding
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../direct/framing.html">
            
                <a href="../direct/framing.html">
            
                    
                    2.3 Framing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../direct/error.html">
            
                <a href="../direct/error.html">
            
                    
                    2.4 Error Detection
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../direct/reliable.html">
            
                <a href="../direct/reliable.html">
            
                    
                    2.5 Reliable Transmission
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../direct/ethernet.html">
            
                <a href="../direct/ethernet.html">
            
                    
                    2.6 Multi-Access Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../direct/wireless.html">
            
                <a href="../direct/wireless.html">
            
                    
                    2.7 Wireless Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.8" data-path="../direct/summary.html">
            
                <a href="../direct/summary.html">
            
                    
                    2.8 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../internetworking/problem.html">
            
                <a href="../internetworking/problem.html">
            
                    
                    Chapter 3: Internetworking
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../internetworking/switching.html">
            
                <a href="../internetworking/switching.html">
            
                    
                    3.1 Switching and Bridging
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../internetworking/basic-ip.html">
            
                <a href="../internetworking/basic-ip.html">
            
                    
                    3.2 Basic Internetworking
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../internetworking/routing.html">
            
                <a href="../internetworking/routing.html">
            
                    
                    3.3 Routing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../internetworking/impl.html">
            
                <a href="../internetworking/impl.html">
            
                    
                    3.4 Implementation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../internetworking/summary.html">
            
                <a href="../internetworking/summary.html">
            
                    
                    3.5 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../scaling/problem.html">
            
                <a href="../scaling/problem.html">
            
                    
                    Chapter 4: Advanced Internetworking
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../scaling/global.html">
            
                <a href="../scaling/global.html">
            
                    
                    4.1 Global Internet
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../scaling/multicast.html">
            
                <a href="../scaling/multicast.html">
            
                    
                    4.2 Multicast
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../scaling/mpls.html">
            
                <a href="../scaling/mpls.html">
            
                    
                    4.3 Multiprotocol Label Switching
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="../scaling/mobile-ip.html">
            
                <a href="../scaling/mobile-ip.html">
            
                    
                    4.4 Routing Among Mobile Devices
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.5" data-path="../scaling/summary.html">
            
                <a href="../scaling/summary.html">
            
                    
                    4.5 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../e2e/problem.html">
            
                <a href="../e2e/problem.html">
            
                    
                    Chapter 5: End-to-End Protocols
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../e2e/udp.html">
            
                <a href="../e2e/udp.html">
            
                    
                    5.1 Simple Demultiplexor (UDP)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../e2e/tcp.html">
            
                <a href="../e2e/tcp.html">
            
                    
                    5.2 Reliable Byte Stream (TCP)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../e2e/rpc.html">
            
                <a href="../e2e/rpc.html">
            
                    
                    5.3 Remote Procedure Call
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../e2e/rtp.html">
            
                <a href="../e2e/rtp.html">
            
                    
                    5.4 Transport for Real-Time Applications (RTP)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.5" data-path="../e2e/summary.html">
            
                <a href="../e2e/summary.html">
            
                    
                    5.5 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="problem.html">
            
                <a href="problem.html">
            
                    
                    Chapter 6: Congestion Control and Resource Allocation
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="issues.html">
            
                <a href="issues.html">
            
                    
                    6.1 Issues in Resource Allocation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="queuing.html">
            
                <a href="queuing.html">
            
                    
                    6.2 Queuing Disciplines
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.7.3" data-path="tcpcc.html">
            
                <a href="tcpcc.html">
            
                    
                    6.3 TCP Congestion Control
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="avoidance.html">
            
                <a href="avoidance.html">
            
                    
                    6.4 Congestion-Avoidance Mechanisms
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="qos.html">
            
                <a href="qos.html">
            
                    
                    6.5 Quality of Service
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.6" data-path="summary.html">
            
                <a href="summary.html">
            
                    
                    6.6 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../data/problem.html">
            
                <a href="../data/problem.html">
            
                    
                    Chapter 7: End-to-End Data
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../data/presentation.html">
            
                <a href="../data/presentation.html">
            
                    
                    7.1 Presentation Formatting
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="../data/multimedia.html">
            
                <a href="../data/multimedia.html">
            
                    
                    7.2 Multimedia Data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="../data/summary.html">
            
                <a href="../data/summary.html">
            
                    
                    7.3 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../security/problem.html">
            
                <a href="../security/problem.html">
            
                    
                    Chapter 8: Network Security
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../security/crypto.html">
            
                <a href="../security/crypto.html">
            
                    
                    8.1 Cryptographic Building Blocks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../security/key-distro.html">
            
                <a href="../security/key-distro.html">
            
                    
                    8.2 Key Predistribution
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.3" data-path="../security/authentication.html">
            
                <a href="../security/authentication.html">
            
                    
                    8.3 Authentication Protocols
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.4" data-path="../security/systems.html">
            
                <a href="../security/systems.html">
            
                    
                    8.4 Example Systems
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.5" data-path="../security/summary.html">
            
                <a href="../security/summary.html">
            
                    
                    8.5 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../applications/problem.html">
            
                <a href="../applications/problem.html">
            
                    
                    Chapter 9: Applications
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../applications/traditional.html">
            
                <a href="../applications/traditional.html">
            
                    
                    9.1 Traditional Applications
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.2" data-path="../applications/multimedia.html">
            
                <a href="../applications/multimedia.html">
            
                    
                    9.2 Multimedia Applications
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.3" data-path="../applications/infrastructure.html">
            
                <a href="../applications/infrastructure.html">
            
                    
                    9.3 Infrastructure Applications
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.4" data-path="../applications/overlays.html">
            
                <a href="../applications/overlays.html">
            
                    
                    9.4 Overlay Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.5" data-path="../applications/summary.html">
            
                <a href="../applications/summary.html">
            
                    
                    9.5 Summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >6.3 TCP Congestion Control</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="63-tcp-congestion-control">6.3 TCP Congestion Control</h1>
<p>This section describes the predominant example of end-to-end congestion
control in use today, that implemented by TCP. The essential strategy of
TCP is to send packets into the network without a reservation and then
to react to observable events that occur. TCP assumes only FIFO queuing
in the network&apos;s routers, but also works with fair queuing.</p>
<p>TCP congestion control was introduced into the Internet in the late
1980s by Van Jacobson, roughly eight years after the TCP/IP protocol
stack had become operational. Immediately preceding this time, the
Internet was suffering from congestion collapse&#x2014;hosts would send their
packets into the Internet as fast as the advertised window would allow,
congestion would occur at some router (causing packets to be dropped),
and the hosts would time out and retransmit their packets, resulting in
even more congestion.</p>
<p>Broadly speaking, the idea of TCP congestion control is for each source
to determine how much capacity is available in the network, so that it
knows how many packets it can safely have in transit. Once a given
source has this many packets in transit, it uses the arrival of an ACK
as a signal that one of its packets has left the network and that it is
therefore safe to insert a new packet into the network without adding to
the level of congestion. By using ACKs to pace the transmission of
packets, TCP is said to be <em>self-clocking</em>. Of course, determining the
available capacity in the first place is no easy task. To make matters
worse, because other connections come and go, the available bandwidth
changes over time, meaning that any given source must be able to adjust
the number of packets it has in transit. This section describes the
algorithms used by TCP to address these and other problems.</p>
<p>Note that, although we describe the TCP congestion-control mechanisms
one at a time, thereby giving the impression that we are talking about
three independent mechanisms, it is only when they are taken as a whole
that we have TCP congestion control. Also, while we are going to begin
here with the variant of TCP congestion control most often referred to
as <em>standard TCP</em>, we will see that there are actually quite a few
variants of TCP congestion control in use today, and researchers
continue to explore new approaches to addressing this problem. Some of
these new approaches are discussed below.</p>
<h2 id="additive-increasemultiplicative-decrease">Additive Increase/Multiplicative Decrease</h2>
<p>TCP maintains a new state variable for each connection, called
<code>CongestionWindow</code>, which is used by the source to limit how much data
it is allowed to have in transit at a given time. The congestion window
is congestion control&apos;s counterpart to flow control&apos;s advertised window.
TCP is modified such that the maximum number of bytes of unacknow-
ledged data allowed is now the minimum of the congestion window and the
advertised window. Thus, using the variables defined in the previous
chapter, TCP&apos;s effective window is revised as follows:</p>
<pre><code class="lang-pseudo">MaxWindow = MIN(CongestionWindow, AdvertisedWindow)
EffectiveWindow = MaxWindow -  (LastByteSent - LastByteAcked)
</code></pre>
<p>That is, <code>MaxWindow</code> replaces <code>AdvertisedWindow</code> in the calculation
of <code>EffectiveWindow</code>. Thus, a TCP source is allowed to send no
faster than the slowest component&#x2014;the network or the destination
host&#x2014;can accommodate.</p>
<p>The problem, of course, is how TCP comes to learn an appropriate value
for <code>CongestionWindow</code>. Unlike the <code>AdvertisedWindow</code>, which is sent
by the receiving side of the connection, there is no one to send a
suitable <code>CongestionWindow</code> to the sending side of TCP. The answer is
that the TCP source sets the <code>CongestionWindow</code> based on the level of
congestion it perceives to exist in the network. This involves
decreasing the congestion window when the level of congestion goes up
and increasing the congestion window when the level of congestion goes
down. Taken together, the mechanism is commonly called <em>additive
increase/multiplicative decrease</em> (AIMD); the reason for this mouthful
of a name will become apparent below.</p>
<p>The key question, then, is how does the source determine that the
network is congested and that it should decrease the congestion window?
The answer is based on the observation that the main reason packets are
not delivered, and a timeout results, is that a packet was dropped due
to congestion. It is rare that a packet is dropped because of an error
during transmission. Therefore, TCP interprets timeouts as a sign of
congestion and reduces the rate at which it is transmitting.
Specifically, each time a timeout occurs, the source sets
<code>CongestionWindow</code> to half of its previous value. This halving of the
<code>CongestionWindow</code> for each timeout corresponds to the &quot;multiplicative
decrease&quot; part of AIMD.</p>
<p>Although <code>CongestionWindow</code> is defined in terms of bytes, it is
easiest to understand multiplicative decrease if we think in terms of
whole packets. For example, suppose the <code>CongestionWindow</code> is
currently set to 16 packets. If a loss is detected, <code>CongestionWindow</code>
is set to 8. (Normally, a loss is detected when a timeout occurs, but as
we see below, TCP has another mechanism to detect dropped packets.)
Additional losses cause <code>CongestionWindow</code> to be reduced to 4, then 2,
and finally to 1 packet. <code>CongestionWindow</code> is not allowed to fall
below the size of a single packet, or in TCP terminology, the <em>maximum
segment size</em> .</p>
<figure class="line">
    <a id="linear"></a>
    <img src="figures/f06-08-9780123850591.png" width="200px">
    <figcaption>Packets in transit during additive increase, with one 
    packet being added each RTT.</figcaption>
</figure>

<p>A congestion-control strategy that only decreases the window size is
obviously too conservative. We also need to be able to increase the
congestion window to take advantage of newly available capacity in the
network. This is the &quot;additive increase&quot; part of AIMD, and it works as
follows. Every time the source successfully sends a
<code>CongestionWindow</code>&apos;s worth of packets&#x2014;that is, each packet sent out
during the last round-trip time (RTT) has been ACKed&#x2014;it adds the
equivalent of 1 packet to <code>CongestionWindow</code>. This linear increase is
illustrated in <a href="#linear">Figure 1</a>. Note that, in practice, TCP does
not wait for an entire window&apos;s worth of ACKs to add 1 packet&apos;s worth to
the congestion window, but instead increments <code>CongestionWindow</code> by a
little for each ACK that arrives. Specifically, the congestion window is
incremented as follows each time an ACK arrives:</p>
<pre><code class="lang-pseudo">Increment = MSS x (MSS/CongestionWindow)
CongestionWindow += Increment
</code></pre>
<p>That is, rather than incrementing <code>CongestionWindow</code> by an entire
<code>MSS</code> bytes each RTT, we increment it by a fraction of <code>MSS</code> every
time an ACK is received. Assuming that each ACK acknowledges the receipt
of <code>MSS</code> bytes, then that fraction is .</p>
<figure class="line">
    <a id="sawtooth"></a>
    <img src="figures/f06-09-9780123850591.png" width="600px">
    <figcaption>Typical TCP sawtooth pattern.</figcaption>
</figure>

<p>This pattern of continually increasing and decreasing the congestion
window continues throughout the lifetime of the connection. In fact, if
you plot the current value of <code>CongestionWindow</code> as a function of
time, you get a sawtooth pattern, as illustrated in
<a href="#sawtooth">Figure 2</a>. The important concept to understand about AIMD
is that the source is willing to reduce its congestion window at a much
faster rate than it is willing to increase its congestion window. This
is in contrast to an additive increase/additive decrease strategy in
which the window would be increased by 1 packet when an ACK arrives and
decreased by 1 when a timeout occurs. It has been shown that AIMD is a
necessary condition for a congestion-control mechanism to be stable (see
the Further Reading section). One intuitive reason to decrease the
window aggressively and increase it conservatively is that the
consequences of having too large a window are much worse than those of
it being too small. For example, when the window is too large, packets
that are dropped will be retransmitted, making congestion even worse;
thus, it is important to get out of this state quickly.</p>
<p>Finally, since a timeout is an indication of congestion that triggers
multiplicative decrease, TCP needs the most accurate timeout mechanism
it can afford. We already covered TCP&apos;s timeout mechanism in an earlier
chapter, so we do not repeat it here. The two main things to remember
about that mechanism are that (1) timeouts are set as a function of both
the average RTT and the standard deviation in that average, and (2) due
to the cost of measuring each transmission with an accurate clock, TCP
only samples the round-trip time once per RTT (rather than once per
packet) using a coarse-grained (500-ms) clock.</p>
<h2 id="slow-start">Slow Start</h2>
<p>The additive increase mechanism just described is the right approach to
use when the source is operating close to the available capacity of the
network, but it takes too long to ramp up a connection when it is
starting from scratch. TCP therefore provides a second mechanism,
ironically called <em>slow start</em>, which is used to increase the
congestion window rapidly from a cold start. Slow start effectively
increases the congestion window exponentially, rather than linearly.</p>
<p>Specifically, the source starts out by setting <code>CongestionWindow</code> to
one packet. When the ACK for this packet arrives, TCP adds 1 to
<code>CongestionWindow</code> and then sends two packets. Upon receiving the
corresponding two ACKs, TCP increments <code>CongestionWindow</code> by 2&#x2014;one
for each ACK&#x2014;and next sends four packets. The end result is that TCP
effectively doubles the number of packets it has in transit every RTT.
<a href="#exponential">Figure 3</a> shows the growth in the number of packets in
transit during slow start. Compare this to the linear growth of additive
increase illustrated in <a href="#linear">Figure 1</a>.</p>
<figure class="line">
    <a id="exponential"></a>
    <img src="figures/f06-10-9780123850591.png" width="200px">
    <figcaption>Packets in transit during slow start.</figcaption>
</figure>

<p>Why any exponential mechanism would be called &quot;slow&quot; is puzzling at
first, but it can be explained if put in the proper historical context.
We need to compare slow start not against the linear mechanism of the
previous subsection, but against the original behavior of TCP. Consider
what happens when a connection is established and the source first
starts to send packets&#x2014;that is, when it currently has no packets in
transit. If the source sends as many packets as the advertised window
allows&#x2014;which is exactly what TCP did before slow start was
developed&#x2014;then even if there is a fairly large amount of bandwidth
available in the  network, the routers may not be able to consume this
burst of packets. It all depends on how much buffer space is available
at the routers. Slow start was therefore designed to space packets out
so that this burst does not occur. In other words, even though its
exponential growth is faster than linear growth, slow start is much
&quot;slower&quot; than sending an entire advertised window&apos;s worth of data all at
once.</p>
<p>There are actually two different situations in which slow start runs.
The first is at the very beginning of a connection, at which time the
source has no idea how many packets it is going to be able to have in
transit at a given time. (Keep in mind that TCP runs over everything
from 9600-bps links to 2.4-Gbps links, so there is no way for the source
to know the network&apos;s capacity.) In this situation, slow start continues
to double <code>CongestionWindow</code> each RTT until there is a loss, at which
time a timeout causes multiplicative decrease to divide
<code>CongestionWindow</code> by 2.</p>
<p>The second situation in which slow start is used is a bit more subtle;
it occurs when the connection goes dead while waiting for a timeout to
occur. Recall how TCP&apos;s sliding window algorithm works&#x2014;when a packet
is lost, the source eventually reaches a point where it has sent as much
data as the advertised window allows, and so it blocks while waiting for
an ACK that will not arrive. Eventually, a timeout happens, but by this
time there are no packets in transit, meaning that the source will
receive no ACKs to &quot;clock&quot; the transmission of new packets. The source
will instead receive a single cumulative ACK that reopens the entire
advertised window, but, as explained above, the source then uses slow
start to restart the flow of data rather than dumping a whole window&apos;s
worth of data on the network all at once.</p>
<p>Although the source is using slow start again, it now knows more
information than it did at the beginning of a connection. Specifically,
the source has a current (and useful) value of <code>CongestionWindow</code>;
this is the value of <code>CongestionWindow</code> that existed prior to the last
packet loss, divided by 2 as a result of the loss. We can think of this
as the <em>target</em> congestion window. Slow start is used to rapidly
increase the sending rate up to this value, and then additive increase
is used beyond this point. Notice that we have a small bookkeeping
problem to take care of, in that we want to remember the target
congestion window resulting from multiplicative decrease as well as the
<em>actual</em> congestion window being used by slow start. To address this
problem, TCP introduces a temporary variable to store the target window,
typically called <code>CongestionThreshold</code>, that is set equal to the
<code>CongestionWindow</code> value that results from multiplicative decrease.
The variable <code>CongestionWindow</code> is then reset to one packet, and it is
incremented by one packet for every ACK that is received until it
reaches <code>CongestionThreshold</code>, at which point it is incremented by one
packet per RTT.</p>
<p>In other words, TCP increases the congestion window as defined by the
following code fragment:</p>
<pre><code class="lang-c">{
    u_int    cw = state-&gt;CongestionWindow;
    u_int    incr = state-&gt;maxseg;

    <span class="hljs-keyword">if</span> (cw &gt; state-&gt;CongestionThreshold)
        incr = incr * incr / cw;
    state-&gt;CongestionWindow = MIN(cw + incr, TCP_MAXWIN);
}
</code></pre>
<p>where <code>state</code> represents the state of a particular TCP connection and
defines an upper bound on how large the congestion window is allowed to
grow.</p>
<p><a href="#trace1">Figure 4</a> traces how TCP&apos;s <code>CongestionWindow</code> increases and
decr- eases over time and serves to illustrate the interplay of slow
start and additive increase/multiplicative decrease. This trace was
taken from an actual TCP connection and shows the current value of
<code>CongestionWindow</code>&#x2014;the colored line&#x2014;over time.</p>
<figure class="line">
    <a id="trace1"></a>
    <img src="figures/f06-11-9780123850591.png" width="600px">
    <figcaption>Behavior of TCP congestion control. Colored line = value
    of `CongestionWindow` over time; solid bullets at top of graph
    = timeouts; hash marks at top of graph = time when each packet is
    transmitted; vertical bars = time when a packet that was
    eventually retransmitted was first transmitted.</figcaption>
</figure>

<p>There are several things to notice about this trace. The first is the
rapid increase in the congestion window at the beginning of the
connection. This corresponds to the initial slow start phase. The slow
start phase continues until several packets are lost at about 0.4
seconds into the connection, at which time <code>CongestionWindow</code> flattens
out at about 34 KB. (Why so many packets are lost during slow start is
discussed below.) The reason why the congestion window flattens is that
there are no ACKs arriving, due to the fact that several packets were
lost. In fact, no new packets are sent during this time, as denoted by
the lack of hash marks at the top of the graph. A timeout eventually
happens at approximately 2 seconds, at which time the congestion window
is divided by 2 (i.e., cut from approximately 34 KB to around 17 KB) and
<code>CongestionThreshold</code> is set to this value. Slow start then causes
<code>CongestionWindow</code> to be reset to one packet and to start ramping up
from there.</p>
<p>There is not enough detail in the trace to see exactly what happens when
a couple of packets are lost just after 2 seconds, so we jump ahead to
the linear increase in the congestion window that occurs between 2 and
4 seconds. This corresponds to additive increase. At about 4 seconds,
<code>CongestionWindow</code> flattens out, again due to a lost packet. Now, at
about 5.5 seconds:</p>
<ol>
<li><p>A timeout happens, causing the congestion window to be divided by 2,
 dropping it from approximately 22 KB to 11 KB, and
 <code>CongestionThreshold</code> is set to this amount.</p>
</li>
<li><p><code>CongestionWindow</code> is reset to one packet, as the sender enters
 slow start.</p>
</li>
<li><p>Slow start causes <code>CongestionWindow</code> to grow exponentially until
 it reaches <code>CongestionThreshold</code>.</p>
</li>
<li><p><code>CongestionWindow</code> then grows linearly.</p>
</li>
</ol>
<p>The same pattern is repeated at around 8 seconds when another timeout
occurs.</p>
<p>We now return to the question of why so many packets are lost during the
initial slow start period. At this point, TCP is attempting to learn how
much bandwidth is available on the network. This is a very difficult
task. If the source is not aggressive at this stage&#x2014;for example, if it
only increases the congestion window linearly&#x2014;then it takes a long
time for it to discover how much bandwidth is available. This can have a
dramatic impact on the throughput achieved for this connection. On the
other hand, if the source is aggressive at this stage, as TCP is during
exponential growth, then the source runs the risk of having half a
window&apos;s worth of packets dropped by the network.</p>
<p>To see what can happen during exponential growth, consider the situation
in which the source was just able to successfully send 16 packets
through the network, causing it to double its congestion window to 32.
Suppose, however, that the network happens to have just enough capacity
to support 16 packets from this source. The likely result is that 16 of
the 32 packets sent under the new congestion window will be dropped by
the network; actually, this is the worst-case outcome, since some of the
packets will be buffered in some router. This problem will become
increasingly severe as the <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>y</mi><mo>&#xD7;</mo><mi>b</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>w</mi><mi>i</mi><mi>d</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">delay \times bandwidth</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mbin">&#xD7;</span><span class="mord mathit">b</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">d</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathit">i</span><span class="mord mathit">d</span><span class="mord mathit">t</span><span class="mord mathit">h</span></span></span></span> product
of networks increases. For example, a <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>y</mi><mo>&#xD7;</mo><mi>b</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>w</mi><mi>i</mi><mi>d</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">delay \times bandwidth</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mbin">&#xD7;</span><span class="mord mathit">b</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">d</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathit">i</span><span class="mord mathit">d</span><span class="mord mathit">t</span><span class="mord mathit">h</span></span></span></span>
product of 500 KB means that each
connection has the potential to lose up to 500 KB of data at the
beginning of each connection. Of course, this assumes that both the
source and the destination implement the &quot;big windows&quot; extension.</p>
<p>Some protocol designers have proposed alternatives to slow start,
whereby the source tries to estimate the available bandwidth by more
sophisticated means. A recent example is the <em>quick-start</em> mechanism
undergoing standardization at the IETF. The basic idea is that a TCP
sender can ask for an initial sending rate greater than slow start would
allow by putting a requested rate in its SYN packet as an IP option.
Routers along the path can examine the option, evaluate the current
level of congestion on the outgoing link for this flow, and decide if
that rate is acceptable, if a lower rate would be acceptable, or if
standard slow start should be used. By the time the SYN reaches the
receiver, it will contain either a rate that was acceptable to all
routers on the path or an indication that one or more routers on the
path could not support the quick-start request. In the former case, the
TCP sender uses that rate to begin transmission; in the latter case, it
falls back to standard slow start. If TCP is allowed to start off
sending at a higher rate, a session could more quickly reach the point
of filling the pipe, rather than taking many round-trip times to do so.</p>
<p>Clearly one of the challenges to this sort of enhancement to TCP is that
it requires substantially more cooperation from the routers than
standard TCP does. If a single router in the path does not support
quick-start, then the system reverts to standard slow start. Thus, it
could be a long time before these types of enhancements could make it
into the Internet; for now, they are more likely to be used in
controlled network environments (e.g., research networks).</p>
<h2 id="fast-retransmit-and-fast-recovery">Fast Retransmit and Fast Recovery</h2>
<p>The mechanisms described so far were part of the original proposal to
add congestion control to TCP. It was soon discovered, however, that the
coarse-grained implementation of TCP timeouts led to long periods of
time during which the connection went dead while waiting for a timer to
expire. Because of this, a new mechanism called <em>fast retransmit</em> was
added to TCP. Fast retransmit is a heuristic that sometimes triggers the
retransmission of a dropped packet sooner than the regular timeout
mechanism. The fast retransmit mechanism does not replace regular
timeouts; it just enhances that facility.</p>
<p>The idea of fast retransmit is straightforward. Every time a data packet
arrives at the receiving side, the receiver responds with an
acknowledgment, even if this sequence number has already been
acknowledged. Thus, when a packet arrives out of order&#x2014;when TCP cannot
yet acknowledge the data the packet contains because earlier data has
not yet arrived&#x2014;TCP resends the same acknowledgment it sent the last
time. This second transmission of the same acknowledgment is called a
<em>duplicate ACK</em>. When the sending side sees a duplicate ACK, it knows
that the other side must have received a packet out of order, which
suggests that an earlier packet might have been lost. Since it is also
possible that the earlier packet has only been delayed rather than lost,
the sender waits until it sees some number of duplicate ACKs and then
retransmits the missing packet. In practice, TCP waits until it has seen
three duplicate ACKs before retransmitting the packet.</p>
<figure class="line">
    <a id="tcp-fast"></a>
    <img src="figures/f06-12-9780123850591.png" width="300px">
    <figcaption>Fast retransmit based on duplicate ACKs.</figcaption>
</figure>

<p><a href="#tcp-fast">Figure 5</a> illustrates how duplicate ACKs lead to a fast
retransmit. In this example, the destination receives packets 1 and 2,
but packet 3 is lost in the network. Thus, the destination will send a
duplicate ACK for packet 2 when packet 4 arrives, again when packet 5
arrives, and so on. (To simplify this example, we think in terms of
packets 1, 2, 3, and so on, rather than worrying about the sequence
numbers for each byte.) When the sender sees the third duplicate ACK for
packet 2&#x2014;the one sent because the receiver had gotten packet 6&#x2014;it
retransmits packet 3. Note that when the retransmitted copy of packet 3
arrives at the destination, the receiver then sends a cumulative ACK for
everything up to and including packet 6 back to the source.</p>
<figure class="line">
    <a id="trace2"></a>
    <img src="figures/f06-13-9780123850591.png" width="600px">
    <figcaption>Trace of TCP with fast retransmit. Colored line
    =`CongestionWindow`; solid bullet = timeout; hash marks = time
    when each packet is transmitted; vertical bars = time when a
    packet that was eventually retransmitted was first
    transmitted.</figcaption>
</figure>

<p><a href="#trace2">Figure 6</a> illustrates the behavior of a version of TCP with
the fast retransmit mechanism. It is interesting to compare this trace
with that given in <a href="#trace1">Figure 4</a>, where fast retransmit was not
implemented&#x2014;the long periods during which the congestion window stays
flat and no packets are sent has been eliminated. In general, this
technique is able to eliminate about half of the coarse-grained timeouts
on a typical TCP connection, resulting in roughly a 20% improvement in
the throughput over what could otherwise have been achieved. Notice,
however, that the fast retransmit strategy does not eliminate all
coarse-grained timeouts. This is because for a small window size there
will not be enough packets in transit to cause enough duplicate ACKs to
be delivered. Given enough lost packets&#x2014;for example, as happens during
the initial slow start phase&#x2014;the sliding window algorithm eventually
blocks the sender until a timeout occurs. Given the current 64-KB
maximum advertised window size, TCP&apos;s fast retransmit mechanism is able
to detect up to three dropped packets per window in practice.</p>
<p>Finally, there is one last improvement we can make. When the fast
retransmit mechanism signals congestion, rather than drop the congestion
window all the way back to one packet and run slow start, it is possible
to use the ACKs that are still in the pipe to clock the sending of
packets. This mechanism, which is called <em>fast recovery</em>, effectively
removes the slow start phase that happens between when fast retransmit
detects a lost packet and additive increase begins. For example, fast
recovery avoids the slow start period between 3.8 and 4 seconds in
<a href="#trace2">Figure 6</a> and instead simply cuts the congestion window in
half (from 22 KB to 11 KB) and resumes additive increase. In other
words, slow start is only used at the beginning of a connection and
whenever a coarse-grained timeout occurs. At all other times, the
congestion window is following a pure additive increase/multiplicative
decrease pattern.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="queuing.html" class="navigation navigation-prev " aria-label="Previous page: 6.2 Queuing Disciplines">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="avoidance.html" class="navigation navigation-next " aria-label="Next page: 6.4 Congestion-Avoidance Mechanisms">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"6.3 TCP Congestion Control","level":"1.7.3","depth":2,"next":{"title":"6.4 Congestion-Avoidance Mechanisms","level":"1.7.4","depth":2,"path":"congestion/avoidance.md","ref":"congestion/avoidance.md","articles":[]},"previous":{"title":"6.2 Queuing Disciplines","level":"1.7.2","depth":2,"path":"congestion/queuing.md","ref":"congestion/queuing.md","articles":[]},"dir":"ltr"},"config":{"plugins":["anchorjs","katex","block-align","sequence-diagrams","creativecommons","custom-favicon","smart-nav-collapse"],"root":".","styles":{"website":"styles/website.css","pdf":"styles/pdf.css"},"pluginsConfig":{"block-align":{},"search":{},"sequence-diagrams":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"katex":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"favicon":"bridge.ico","custom-favicon":{},"creativecommons":{},"smart-nav-collapse":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchorjs":{}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{"branch":"master"},"title":"Computer Networks: A Systems Approach","gitbook":"*"},"file":{"path":"congestion/tcpcc.md","mtime":"2018-08-15T22:10:01.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2018-08-21T22:47:21.899Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-anchorjs/anchor-style.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-smart-nav-collapse/smart-nav-collapse.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

